{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcEaUXJpTL5i"
      },
      "source": [
        "##Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11Yetzw88TxD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATADIR = 'Dataset/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG0bc7oRTVwZ"
      },
      "source": [
        "##Collection of Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1r1QygSOWGJ7"
      },
      "outputs": [],
      "source": [
        "classes = ['Andy Samberg', 'Chris Evans','Elizabeth_Olsen', 'Scarlett_Johansson']\n",
        "np.random.seed(0)\n",
        "def training_data():\n",
        "  X_train = []\n",
        "  Y_train = []\n",
        "  for i in classes:\n",
        "    path = os.path.join(DATADIR, i)\n",
        "    for img in os.listdir(path)[:75]:\n",
        "      img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "      IMG_SIZE = 100\n",
        "      img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      X_train.append(img_array)\n",
        "      Y_train.append(classes.index(i))\n",
        "  combined_data = list(zip(X_train, Y_train))\n",
        "  np.random.shuffle(combined_data)\n",
        "  X_train_shuff, Y_train_shuff = zip(*combined_data)\n",
        "  X_train = np.array(X_train_shuff)\n",
        "  Y_train = np.array(Y_train_shuff)\n",
        "  return np.array(X_train), np.array(Y_train)\n",
        "X_train, Y_train = training_data()\n",
        "X_train = np.expand_dims(X_train, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhk9QBS_Tfll"
      },
      "source": [
        "## Collection of Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dj5wge9ZYBcI"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "def testing_data():\n",
        "  X_test = []\n",
        "  Y_test = []\n",
        "  for i in classes:\n",
        "    path = os.path.join(DATADIR, i)\n",
        "    for img in os.listdir(path)[75:100]:\n",
        "      img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "      IMG_SIZE = 100\n",
        "      img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "      X_test.append(img_array)\n",
        "      Y_test.append(classes.index(i))\n",
        "  combined_data = list(zip(X_test, Y_test))\n",
        "  np.random.shuffle(combined_data)\n",
        "  X_test_shuff, Y_test_shuff = zip(*combined_data)\n",
        "  X_test = np.array(X_test_shuff)\n",
        "  Y_test = np.array(Y_test_shuff)\n",
        "  return np.array(X_test), np.array(Y_test)\n",
        "X_test, Y_test = testing_data()\n",
        "X_test = np.expand_dims(X_test, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujFZzn5sTj2K"
      },
      "source": [
        "## Normalizing X Data Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WtKBA0qYelg"
      },
      "outputs": [],
      "source": [
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u8MInWrTu4N"
      },
      "source": [
        "## Convolution Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-FXZtqobrgn",
        "outputId": "118eaf70-9daf-466d-c692-ec2a4b2a1158"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 6s 473ms/step - loss: 1.4144 - accuracy: 0.2333\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 5s 538ms/step - loss: 1.3342 - accuracy: 0.3233\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 6s 610ms/step - loss: 1.0857 - accuracy: 0.5233\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 5s 455ms/step - loss: 0.7181 - accuracy: 0.7567\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 6s 631ms/step - loss: 0.4980 - accuracy: 0.8400\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 5s 457ms/step - loss: 0.3578 - accuracy: 0.8700\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 5s 451ms/step - loss: 0.2208 - accuracy: 0.9300\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 7s 685ms/step - loss: 0.1752 - accuracy: 0.9400\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 5s 454ms/step - loss: 0.1134 - accuracy: 0.9767\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 5s 468ms/step - loss: 0.0642 - accuracy: 0.9900\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 7s 707ms/step - loss: 0.0496 - accuracy: 0.9900\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 5s 474ms/step - loss: 0.0584 - accuracy: 0.9867\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 5s 512ms/step - loss: 0.0238 - accuracy: 0.9967\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 6s 602ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 5s 458ms/step - loss: 0.0153 - accuracy: 0.9967\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b759c40cfa0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn = models.Sequential([\n",
        "      layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape = (100,100,1)),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "\n",
        "      layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "      layers.MaxPooling2D((2,2)),\n",
        "\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(128, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(32, activation='relu'),\n",
        "      layers.Dense(4, activation='softmax')\n",
        "])\n",
        "cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "cnn.fit(X_train, Y_train, epochs = 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tjemQMeT6uN"
      },
      "source": [
        "## Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoNvjvqyCIxZ",
        "outputId": "bdccae5c-7240-4748-ee9a-4ad6491ab7f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "models.save_model(cnn, './saved_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjXdmtaQT9bt"
      },
      "source": [
        "## Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_XDTuzGc-p2"
      },
      "outputs": [],
      "source": [
        "load_model = models.load_model('./saved_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCA0KXfLrEFO",
        "outputId": "a50dc569-6d1e-4a8a-db47-13b9baadda80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 86ms/step - loss: 0.3385 - accuracy: 0.9300\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.33849358558654785, 0.9300000071525574]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_model.evaluate(X_test,Y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
